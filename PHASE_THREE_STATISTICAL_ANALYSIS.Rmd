---
title: "PHASE_THREE_STATISTICAL_ANALYSIS"
author: "Chris Low"
date: "01/09/2021"
output: html_document
---

```{r setup, include=FALSE}

library(dplyr) # data visualization
library(tidyverse) # data wrangling and visualization
library(ggplot2) # data visualization
library(performance) # check model outputs
library(lme4) # analysis for logistic regressions and mixed-effects modelling
library(corrplot) # creating a correlation matrix
library(sjPlot) # to visualizing mixed-effects models
library(effects) # to visualizing mixed-effects models
library(report) # mainly for an "report" function
library(emmeans) # post-hoc analysis
library(knitr) # beautifying tables
library(MASS) # model selection using drop terms
library(pscl) # zero-inflation regression models
library(MuMIn) # model comparison
library(DHARMa) # model critism plots
library(effects) # extracting model outputs
library(jtools) # 
library(webshot) # extract SJplots - for tables

```

## Loading in final dataset in r

```{r load data, echo=TRUE}

# Just save priority EDGE lineage list and PD_mammal_merged list as essential for analysis: mammals_pd_merged, EDGE_priority_lineages, ePD_priority_lineages (final datasets so far!!)
load("C:/Users/Student/Zoological Society of London/EDGEofExistence - Chris Low - EDGE lineages/Project II/Data and analysis/EDGE_families_and_scores/EDGE_LINEAGES_FOR_ANALYSIS.RData")

# load dataout datasets with both Upham and Gumbs datasets
load("C:/Users/Student/Zoological Society of London/EDGEofExistence - Chris Low - EDGE lineages/Project II/Data and analysis/Mammal phylogenies/ePD_scores_ALL.RData")

# match up Order with family##############
Order <- read.csv(file = "C:/Users/Student/Zoological Society of London/EDGEofExistence - Chris Low - EDGE lineages/Project II/Data and analysis/EDGE_families_and_scores/Mammal_orders.csv")

Order$Order <- str_to_title(Order$Order)
Order$Family <- str_to_title(Order$Family)

Order <- Order %>% 
  dplyr::select(Family, Order, species) %>% 
  group_by(Order, Family) %>% 
  summarise(richness = sum(length(Order)))

t <- merge(mammals_pd_merged, Order,  by = "Family", all.x = TRUE)

t <- t[,c(1,3:50)]

t <- t %>%
  dplyr::select(Order, everything())

# insert family into NA's
mammals_pd_merged <- t
########################################
```

# Summary statistics of entirly threatened lineages
```{r threatened lienages}

# subset famileis which entire population are threatened with extinction
families_threatened <- mammals_pd_merged[which(mammals_pd_merged$assessed_threat_prop == 1),]

# select important columns
families_threatened <- families_threatened[,c(1:3,7,9,14)]

# sum ePD loss of these families (384 MY)
monotypic_spp <- subset(families_threatened, families_threatened$richness ==1)

# sum ePD of monotypic species (174 MY)
sum(monotypic_spp$Median.exPD)

# caculate conservation staus for mammals in 2008 to see what uplisting there have been since then
uplistming_sub <- RL_change_df[(RL_change_df$Family %in% families_threatened$Family),]

# three families weren't in intial 2008 RL assessment - don't include these as I think they were already highlighted for importance such as Lipotidae (river dolphin)
list(setdiff(families_threatened$Family,uplistming_sub$Family))

# 10 families uplisted since 2008 - 40% of families have had uplistings since 2008
sum(uplistming_sub$prop_uplisted > 0)

# 5 families have have become fully threatened since 2008 (20%)
sum(uplistming_sub$prop_uplisted == 1)

```

## Testing the difference between

You can also embed plots, for example:

```{r testing phylogeny datasets, echo=FALSE}

# Spearmans's rank correaltion between imputted an non-imputed datasets
cor.test(ex_PD_full$Median.exPD, ex_PD_full$Median.ePD.UPHAM, method = "spearman")

# subset variables for analysis
ePD_spp_rich_df <- mammals_pd_merged[,c(3,14,39,49)]

# Spearman's rank correlation between species richness and ePD (rs = 0.67; p < 0.001; N = 160)
cor.test(ePD_spp_rich_df$richness, ePD_spp_rich_df$Median.exPD, method = "spearman") 

# plot for species richness and ePD loss
tiff("C:/Users/Student/Zoological Society of London/EDGEofExistence - Chris Low - EDGE lineages/Project II/Results/Imperilled PD/ePDloss_richness_FINAL.tiff", units = "in", width = 5, height = 4, res = 300)

ggplot(ePD_spp_rich_df, aes(x=richness, y=Median.exPD)) + geom_point(size=2, shape=20) +
  geom_smooth(method=lm, se = FALSE, color = "red") +
  scale_y_log10() +
  scale_x_log10() +
  theme_bw(base_size = 16) +
  labs(y="(Log) Median ePD Loss", x= "(Log) Richness")

dev.off()

# Spearman's rank correaltion for EDGE score (rs = -0.61; p < 0.001; N = 160)
cor.test(ePD_spp_rich_df$richness, ePD_spp_rich_df$median_EDGE, method = "spearman")

# scatterplot for EDGE score and spp richness
tiff("C:/Users/Student/Zoological Society of London/EDGEofExistence - Chris Low - EDGE lineages/Project II/Results/Imperilled PD/EDGE_richness_FINAL.tiff", units = "in", width = 5, height = 4, res = 300)

ggplot(ePD_spp_rich_df, aes(x=richness, y=median_EDGE)) + geom_point(size=2, shape=20) +
  geom_smooth(method=lm, se = FALSE, color = "red") +
  scale_y_log10() +
  scale_x_log10() +
  theme_bw(base_size = 16) +
  labs(y="(Log) Median EDGE Score", x= "(Log) Richness")

dev.off()

# Spearman's rank correaltion for ED scores (rs = -0.73; p < 0.001; N = 160)
cor.test(ePD_spp_rich_df$richness, ePD_spp_rich_df$median_ED, method = "spearman")

# scatterplot for ED and species richness
tiff("C:/Users/Student/Zoological Society of London/EDGEofExistence - Chris Low - EDGE lineages/Project II/Results/Imperilled PD/ED_richness_FINAL.tiff", units = "in", width = 5, height = 4, res = 300)

ggplot(ePD_spp_rich_df, aes(x=richness, y=median_ED)) + geom_point(size=2, shape=20) +
  geom_smooth(method=lm, se = FALSE, color = "red") +
  scale_y_log10() +
  scale_x_log10() +
  theme_bw(base_size = 16) +
  labs(y="(Log) Median ED Score", x= "(Log) Richness")

dev.off()

```
## Question (i) How do intrinsic and extrinsic threats predict ED?

```{r intrinsic and extrinsic threats, echo=TRUE}

# 
ePD_response_df <- mammals_pd_merged[,c(1,2,3:4,9,14,26:39,48:49)]

# visulising distributions of data
# distribution of response variable is poission
par(mfrow=c(3:4))
for(i in 2:23) {
    hist(ePD_response_df[,i], main=names(ePD_response_df)[i])
}

# Calculate number of occurences which are greater than 0 to sum threat data
ePD_response_df$threat_sum <- apply(ePD_response_df[,c("prop_1_1","prop_2_1","prop_2_3","prop_5_1","prop_5_3","prop_8_1")], 1, function(x) length(which(x > 0)))

# create cum sum of threats as a proportion
ePD_response_df <- ePD_response_df %>% 
  group_by(Family) %>% 
  mutate(threat_sum_prop = threat_sum/6)

# check colinearity of data
# creating a correlation matrix
correlations <- cor(ePD_response_df[,3:24])
corrplot(correlations, method="circle")

ePD_response_df <- ePD_response_df[complete.cases(ePD_response_df),]

# run a glm- MAXIMAL MODEL
ED_glm_full <- glm(log(median_ED + 1) ~ log(bodysize_mean + 1) + log(Gen_length_days +1) + prop_1_1 + prop_2_1 + prop_2_3 + prop_5_1 + prop_5_3 + prop_8_1 + threat_sum_prop, 
              family = gaussian,
              na.action = "na.fail",
              data = ePD_response_df) 

summary(ED_glm_full)

tab_model(ED_glm_full)

# find out explanatory power
with(summary(ED_glm_full), 1 - deviance/null.deviance)

# check model performance - assumptions not violated - no they are not xx
check_model(ED_glm_full)

model_selction <- step(ED_glm_full, direction = "backward")

# update the new model
ED_glm_new <- glm(formula = log(median_ED + 1) ~ prop_2_3 + prop_5_3 + prop_8_1 + 
    threat_sum_prop, family = gaussian, data = ePD_response_df, na.action = "na.fail")

tab_model(ED_glm_new)

# find out explanatory power
with(summary(ED_glm_new), 1 - deviance/null.deviance)

# Using anova to compare model fits - keep full model as it has the highest explanatory power
anova(ED_glm_new, ED_glm_full, test = "F")

# create null model
ED_null <- glm(log(median_ED + 1) ~ 1, data = ePD_response_df)

anova(ED_glm_full, ED_null, test = "F")

# Lastly- check model assumptions 
check_model(ED_glm_full)

### create tabular format or results
tab_model(file = "ED_glm_table.html",
  ED_glm_full,
  CSS = list(
    css.depvarhead = 'color: black;',
    css.centeralign = 'text-align: left;', 
    css.firsttablecol = 'font-weight: bold;', 
    css.summary = 'color: black;'
  )
)

webshot("ED_glm_table.html", "ED_glm_table.png")

# Plotting the response of ED
# pull out the significant effects of the model



plot_model(ED_glm_full, type = "pred", terms = c("prop_2_3", "prop_5_3", "prop_8_1"))

plot_grid(p)

```


# Check if intrinsic and extrintic threats respond to EDGE score
# run a glm with EDGE score as the response variable- MAXIMAL MODEL
EDGE_glm_full <- glm(log(median_EDGE + 1) ~ log(bodysize_mean + 1) + log(Gen_length_days +1) + prop_1_1 + prop_2_1 + prop_2_3 + prop_5_1 + prop_5_3 + prop_8_1 + threat_sum, 
              family = gaussian,
              na.action = "na.fail",
              data = ePD_response_df) 

# get model summary
summary(EDGE_glm_full)

# find out explanatory power
with(summary(EDGE_glm_full), 1 - deviance/null.deviance)

# check model performance - assumptions not violated - no they are not xx
check_model(EDGE_glm_full)

# backwards stepwise model selection
model_selction_EDGE <- step(ED_glm, direction = "backward")

EDGE_glm_update <- glm(log(median_EDGE + 1) ~ prop_2_3 + prop_5_3 + prop_8_1 + threat_sum, 
                       family = gaussian,
                       na.action = "na.fail",
                       data = ePD_response_df) 

# get model summary
summary(EDGE_glm_update)

# find out explanatory power
with(summary(EDGE_glm_update), 1 - deviance/null.deviance)

# Compare full and updated model- USE FULL MODEL
anova(EDGE_glm_full, EDGE_glm_update, test = "F")

# Create null model
EDGE_glm_null <- glm(log(median_EDGE + 1) ~ 1, 
                       family = gaussian,
                       na.action = "na.fail",
                       data = ePD_response_df) 

# compare full model to the null
anova(EDGE_glm_full, EDGE_glm_null, test = "F")

### plotting outputs for EDGE scores and extrinsic threats
### create tabular format or results
tab_model(file = "EDGE_glm_table.html",
  EDGE_glm_full,
  CSS = list(
    css.depvarhead = 'color: black;',
    css.centeralign = 'text-align: left;', 
    css.firsttablecol = 'font-weight: bold;', 
    css.summary = 'color: black;'
  )
)

webshot("EDGE_glm_table.html", "EDGE_glm_table.png")

plot_model(EDGE_glm_full, type = "pred", terms = "prop_8_1")

# now try glmm to see if it can explain any additional variation
# building a mixed-effects linear logistic regression
ePD_response_df$Order <- factor(ePD_response_df$Order)

m <- lmer(log(median_ED +1) ~ log(Gen_length_days +1)  + threat_sum + prop_2_1 + prop_2_3 + prop_5_1 + prop_5_3 + prop_8_1 + (1 | Order), data = ePD_response_df)

summary(m)

check_model(m)

StatisticalModels::R2GLMER(m)


print(summary(m),correlation=FALSE)

tab_model(m)

confint(m)
ranef(m)

print(m)

m_null <- lmer(log(median_ED +1) ~ 1 + (1 | Order), REML = FALSE, data = ePD_response_df)

summary(m_null)

anova(m, m_null)

confint(m)

ranef(m)

print(anova(m))

### Summary- DON'T use LMM modelling 

### Plotting and predicting ED and EDGE scores 

# Plotting the response of ED and EDGE
# pull out the significant effects of the model
ED_effects_8_1 <- effects::effect(term = c("prop_8_1"), mod = EDGE_glm_full) %>%
  # turn it into a dataframe
  as.data.frame()
# Note that at this point, you can also back-transform your values so looking at actual ED and EDGE scores

# Plotting the response of ED and EDGE
# pull out the significant effects of the model
ED_effects_threats <- effects::effect(term = c("threat_sum"), mod = EDGE_glm_full) %>%
  # turn it into a dataframe
  as.data.frame()
# Note that at this point, you can also back-transform your values so looking at actual ED and EDGE scores

# set up a ggplot
ggplot(ED_effects_5_3) + 
  # plot the average slope (fit) for each land use
  # I've used automatic colouring by land use but you can also specify what colours you want for each land use
  geom_line(aes(x = prop_5_3, y = fit)) +
  # add shading for the confidence intervals for each slope
  geom_ribbon(aes(x = prop_5_3, ymin = lower, ymax = upper), alpha = 0.2) +
  # add the x and y label
  labs(x = "Proportion of families threatened by invasive species" ,y = "log(Median ED)")


#######################################

ED_effects <- allEffects(ED_glm_full)

plot_model(ED_glm, type = "pred", terms = c("prop_8_1", "prop_5_3"))
 
plot_model(ED_glm_full, type = "pred", vars = c("prop_8_1", "prop_5_3"), show.ci = T, facet.grid = T)

summ(ED_glm_full)


tab_model(ED_glm_full, show.intercept = TRUE)

# first save table to html file
tab_model(ED_glm_full, file = "plot.html")

# then take this html file and make .png file
webshot("plot.html", "plot.png")

effect_plot(ED_glm_full, pred = threat_sum, interval = TRUE)

```

## Question (ii) How does the inteaction between EDGE/ED score with proportion of threatened species predict conservation status?


```{r conservation staus, echo=TRUE}

# subset data to only contain population probabilities
con_status_interacts_df <- mammals_pd_merged[,c(1:3,9,11,13,14,21,23,25,39,49)]

names(con_status_interacts_df)

head(con_status_interacts_df)

summary(con_status_interacts_df)

# Remove all NA's from columns
con_status_interacts_df <- con_status_interacts_df[complete.cases(con_status_interacts_df),]

# visulising distibutions of data
par(mfrow=c(4,2))
for(i in 2:8) {
    hist(con_status_interacts_df[,i], main=names(con_status_interacts_df)[i])
}

# creating a correlation matrix
correlations <- cor(con_status_interacts_df[,2:8])
corrplot(correlations, method="circle")

# double check strucutre of dataset
str(con_status_interacts_df)

# glm in which EDGE or ED scores is a responds to proportion of threatened species interacts with threats
# perform a glm fit
con_status_uplisted_glm <- glm(prop_uplisted ~ assessed_threat_prop*median_ED, family = quasibinomial("logit"), data = con_status_interacts_df)

summary(con_status_uplisted_glm)


####################################### GLMM scrap code
con_status_interacts_df$Order <- factor(con_status_interacts_df$Order)

test <- glmer(prop_uplisted ~ assessed_threat_prop*median_ED + (1|Order), family = binomial, data = con_status_interacts_df)

check_model(test)

test_null <- glmer(prop_uplisted ~ (1|Order), family = binomial, data = con_status_interacts_df)

anova(test, test_null)

check_model(test_null)

StatisticalModels::R2GLMER(test)

summary(test)

print(ranef(test))

check_model(test)
###############################################

# Just fitting EDGE score as a predictor
con_status_uplisted_glm_EDGE <- glm(prop_uplisted ~ median_EDGE, family = quasibinomial("logit"), data = con_status_interacts_df)

summary(con_status_uplisted_glm_EDGE)

# get summary of model output
summary(con_status_uplisted_glm)

# get explanatory power of model 
with(summary(con_status_uplisted_glm), 1 - deviance/null.deviance)

# check for model performance
performance::check_model(con_status_uplisted_glm)

# test for overdispersion
overdisp_fun <- function(model) {
    rdf <- df.residual(model)
    rp <- residuals(model,type="pearson")
    Pearson.chisq <- sum(rp^2)
    prat <- Pearson.chisq/rdf
    pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
    c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}

# I think there is overdispersion so fit with a quassipoisson distirbution
overdisp_fun(con_status_uplisted_glm)

# compare with null model
con_status_uplisted_glm_null <- glm(prop_uplisted ~ 1, family = quasibinomial("logit"), data = con_status_interacts_df)

# use anova to compare
anova(con_status_uplisted_glm_null, con_status_uplisted_glm, test = "F")

### create tabular format or results
tab_model(file = "con_status_uplisted_glm.html",
  con_status_uplisted_glm,
  CSS = list(
    css.depvarhead = 'color: red;',
    css.centeralign = 'text-align: left;', 
    css.firsttablecol = 'font-weight: bold;', 
    css.summary = 'color: blue;'
  )
)

webshot("con_status_uplisted_glm.html", "con_status_uplisted_glm.png")


############# exploring stable populations

con_status_stable_glm <- glm(Prop_stab ~ assessed_threat_prop*median_ED, family = quasibinomial("logit"), data = con_status_interacts_df)

summary(con_status_stable_glm)

check_model()

# looking at how the interaction between ED score and proporiton of threatened species predicts conservation status downlistings (improved conservation status)
con_status_downlisted_glm <- glm(prop_downlisted ~ assessed_threat_prop*median_ED, family = quasibinomial("logit"), data = con_status_interacts_df)

con_status_downlisted_glm_EDGE <- glm(prop_downlisted ~ median_EDGE, family = quasibinomial("logit"), data = con_status_interacts_df)

summary(con_status_downlisted_glm_EDGE)

# get model summary
summary(con_status_downlisted_glm)

# get explanatory power
with(summary(con_status_downlisted_glm), 1 - deviance/null.deviance)

# test for overdispersion
overdisp_fun(con_status_downlisted_glm)

# compare to null model
con_status_downlisted_glm_null <- glm(prop_downlisted ~ 1, family = quasibinomial("logit"), data = con_status_interacts_df)

# compare between null and full model
anova(con_status_downlisted_glm, con_status_downlisted_glm_null, test = "F")

### create tabular format or results
tab_model(file = "con_status_downlisted_glm.html",
  con_status_downlisted_glm,
  CSS = list(
    css.depvarhead = 'color: red;',
    css.centeralign = 'text-align: left;', 
    css.firsttablecol = 'font-weight: bold;', 
    css.summary = 'color: blue;'
  )
)

webshot("con_status_downlisted_glm.html", "con_status_downlisted_glm.png")

# LOOKING AT CONSERVATION STATUS THAT HAVE BEEN STABLE
con_status_stable_glm <- glm(prop_stable ~ assessed_threat_prop*median_ED, family = quasibinomial("logit"), data = con_status_interacts_df)

summary(con_status_stable_glm)

check_model(con_status_stable_glm)

with(summary(con_status_stable_glm), 1 - deviance/null.deviance)

# present models in nice format- for tomorrow
tab_model(m_ri, show.aic = T)

```

## Question (iii) How does Is the response of population status/family associated with the concentration of anthropogenic threats for priority lineages (REPHRASE question in the morning)

```{r population trend analysis, echo=TRUE}

#subset threat data
pop_status_df <- mammals_pd_merged[,c(1:3,9,11,13,39,42:46,47,49)]

# Remove all NA's from columns
pop_status_df <- pop_status_df[complete.cases(pop_status_df),]

# visulising distibutions of data
par(mfrow=c(4,2))
for(i in 2:13) {
    hist(pop_status_df[,i], main=names(pop_status_df)[i])
}

# creating a correlation matrix - no correlations between variables. Can therefore dismiss the assumption of non-independence
correlations <- cor(pop_status_df[,2:13])
corrplot(correlations, method="circle")

# glm in which EDGE or ED scores is a responds to proportion of threatened species interacts with threats predict popualtion decline
# perform a glm fit
pop_status_dec_glm <- glm(Prop_dec ~ assessed_threat_prop*median_ED, family = quasibinomial("logit"), data = pop_status_df)


# get model summary
summary(pop_status_dec_glm)

# get explanatory power
with(summary(pop_status_dec_glm), 1 - deviance/null.deviance)

# test for overdispersion
overdisp_fun(pop_status_dec_glm)

# check model performance
check_model(pop_status_dec_glm)

# create null model
pop_status_dec_glm_null <- glm(Prop_dec ~ 1, family = quasibinomial("logit"), data = pop_status_df)

# compare full and reduced model
anova(pop_status_dec_glm, pop_status_dec_glm_null, test = "F")

### create tabular format or results
tab_model(file = "pop_status_dec_glm.html",
  pop_status_dec_glm,
  CSS = list(
    css.depvarhead = 'color: red;',
    css.centeralign = 'text-align: left;', 
    css.firsttablecol = 'font-weight: bold;', 
    css.summary = 'color: blue;'
  )
)

webshot("pop_status_dec_glm.html", "pop_status_dec_glm.png")

#################################################
### Look at EDGE score as the response, but remove threatened species 
pop_status_dec_glm_EDGE <- glm(Prop_dec ~ median_EDGE, family = quasibinomial("logit"), data = pop_status_df)

# get model summary
summary(pop_status_dec_glm_EDGE)

# get explanatory power
with(summary(pop_status_dec_glm_EDGE), 1 - deviance/null.deviance)

# test for overdispersion
overdisp_fun(pop_status_dec_glm)

# check model performance
check_model(pop_status_dec_glm_EDGE)

# create null model
pop_status_dec_glm_null <- glm(Prop_dec ~ 1, family = quasibinomial("logit"), data = pop_status_df)

# compare full and reduced model
anova(pop_status_dec_glm_EDGE, pop_status_dec_glm_null, test = "F")

```

```{r pop inc, echo=TRUE}
# now look at glm for population increases
pop_status_inc_glm <- glm(Prop_inc ~ assessed_threat_prop*median_ED, family = quasibinomial("logit"), data = pop_status_df)

# get model summary
summary(pop_status_inc_glm)

# get explanatory power
with(summary(pop_status_inc_glm), 1 - deviance/null.deviance)

# test for overdispersion
overdisp_fun(pop_status_dec_glm)

# check model performance
check_model(pop_status_inc_glm)

# create null model
pop_status_inc_glm_null <- glm(Prop_inc ~ 1, family = quasibinomial("logit"), data = pop_status_df)

# compare full and null model
anova(pop_status_inc_glm, pop_status_inc_glm_null, test = "F")

# compare full and reduced model
anova(pop_status_dec_glm, pop_status_dec_glm_null, test = "F")

### Populations stable 
pop_status_stab_glm <- glm(Prop_stab ~ LC_NT_prop*median_ED, family = quasibinomial("logit"), data = pop_status_df)

summary(pop_status_stab_glm)

### create tabular format or results
tab_model(file = "pop_status_inc_glm.html",
  pop_status_inc_glm,
  CSS = list(
    css.depvarhead = 'color: red;',
    css.centeralign = 'text-align: left;', 
    css.firsttablecol = 'font-weight: bold;', 
    css.summary = 'color: blue;'
  )
)

webshot("pop_status_inc_glm.html", "pop_status_inc_glm.png")

```

# Summary data for EDGE lineages
```{r priority lineages, echo=TRUE}

# number of EDGE lineages - 5
sum(EDGE_priority_lineages$no_DD_NE_prop > 0.5)

# percentage of mammals that are over 50% DD_NE threshold
(5/80)*100

# Get lengths of each priority lineage list 
sum(lengths(regmatches(EDGE_priority_lineages$priority_type, gregexpr("Watchlist lineage", EDGE_priority_lineages$priority_type))))

priority_sub <- EDGE_priority_lineages[c(EDGE_priority_lineages$priority_type == "Priority lineage"),]

# Calculate number of occurences which are greater than 0 to sum threat data
priority_sub$threat_sum <- apply(priority_sub[,c("prop_1_1","prop_2_2","prop_2_3","prop_5_1","prop_5_3","prop_8_1")], 1, function(x) length(which(x > 0)))

```
